---
title: "Notes Administrative Register Data"
author: "Henrik-Alexander Schubert"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


```{r, echo = FALSE}
# Load the packages
library(httr)
library(data.table)
library(dtplyr)
library(tidyverse)
library(pander)
#library(microbenchmark)

# Create a tab function
tab <- function(...){
  pander(table(..., useNA = "always"))
}

```

# Introduction

Administrative register data:

 * *administrative* = derived from administrative system
 * *register* = run continuously, full target system
 * *data* = quantitative, rectangular data
 
Examples: population, vital, housing, tax, health, migration registers...


Registers rely on procedures which translate the event or the count into the register data. This evals several steps, filling in forms, sending documents between persons and organisations, writing it into a computer system. This step-wise process has implications for data quality.

### Advantages

1. Size: not just a sample, often large

2. Participation: often compulsory (legally required), sometimes highly incentived

3. Data quality: often no missing values

### Specialities of ARD

* Found data:

    * not collected for research

    * often messy, fragmented, semi-systematic
    
* Big data: often large and complex

### Challenges

* Ethical

  * no informed consent
  
  * misuse of registers

* Legal

  * Data protection laws (e.g. GDPR)
  
  * Limited access and control

* Technical

  * requires a lot of computing power $O(n)$ vs $O(n^2)$
  
  * complexity: format, inconsistencies (variable names, variables, coverage)

* Practical

  * documentation
  
  * Language: Data, documentation, experts

* Quality

  * *Total survey error framework*
  
      * Measurement
      
      * Representation
      
      
  ![Source: Groves et al. 2003, Survey Methodology](Images/error_framework.png)
  
  * sources of error
  
  

# Handling of big data, classic administrative register data


1. Discovery: Learn about the data

2. Structuring: Bring it in a format ready for analysis

3. Cleaning: Edit variables, create new variables, etc.

4. Enriching: Combine with other data soucres

5. Validating: Did the previous steps work as planned?

6. Analysis: Run your analysis


### Example: US birth statistics

First, we are downloading the birth data for the year 1990 form the website (NBER)[https://data.nber.org/natality/]. The data comes as a zip-file.

```{r download-data, eval = FALSE}
# Where is the data?
url <- "https://data.nber.org/natality/1990/natl1990.csv.zip"

# Where to save it?
zipfile <- "C:/users/Lenovo/Tmp/natl1990.csv.zip"

# Download
if(!exists(zipfile)){
GET(url, write_disk(zipfile, overwrite = TRUE)) #, progress() 
}

# Check size: file size in bytes
file.size(zipfile)

```


In the next step, we want to unzip the data. We use the two packages. We use `fread` from the `data.table` package, which does lazy-loading. This means that the data does not get loaded completely into the memory. 

```{r load-data, eval = FALSE}
# Load the data
command <- "unzip -cq"
cmdzip <- paste(command, zipfile)
dat <- fread(cmd=cmdzip)
```


In the next step, we look at the age distribution of mothers and fathers.

```{r, eval = FALSE}
# Age distribution
dat[ , .N, by = dmage]
dat[ , .N, by = dfage]


```


Apparently, there are many missing values for the age of father. We use the average age gap between mothers and fathers to impute the missing age of father.

```{r, eval = FALSE}
# Make father's age missing
dat$dfage <- ifelse(dat$dfage == 99, NA, dat$dfage)

# Estimate the average age distribution of mothers
dat[, age_diff := dmage - dfage]

# Impute 
dat$dfage <- ifelse(is.na(dat$dfage), dat$dmage - 3, dat$dfage)

```


Another issue with the data is that it evals births which occur to women who are not residing the United States.

```{r, eval = FALSE}
# Tabulate
dat[ , .N, by = restatus]

# Remove foreign living births
d <- d[restatus != 4, ]

```


In the next step, we can aggregate the data by age.
```{r, eval = FALSE}
# Using age specific birth counts
mothers <- dat[ .N, by = dmage]
fathers <- dat[ .N, by = dfage]

```


# Complex administrative register data

Question: Whether being in employment or not-employed affects the probability of childbirth.

We are particularly interested in first births.


First, we load the data.

```{r}
# Load the data 
files <- list.files("Data", pattern = "csv$")
names <- str_remove(files, ".csv") 

# Load the files
for(i in seq_along(files)){
  tmp <- fread(paste0("Data/", files[i]))
  assign(names[i], tmp)
}

```


We estimate exposures based on **the population registers**. Then, we add information about `employment` and `parity`.
To do that, we first look at the population files. We look at the data.  


```{r population-register}
# Status
reg_status$Year %>% tab
reg_status$Status %>% tab
reg_status$Gender %>% tab
reg_status$ID %>% unique %>% length
reg_status %>% filter(ID == 4) %>%  view


```


How to define the risk population. People at risk are people in the age range between age 15 and 55.


```{r}
# Create age
reg_status$Age <- reg_status$Year - reg_status$Cohort

# Validate
reg_status$Age %>% tab

# Drop persons above age 50 and who are above 15
exp <- reg_status %>% filter(Age %in% 15:50)

```

